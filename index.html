<!DOCTYPE html
    PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Consistent Depth of Moving Objects in Video</title>
    <link href="./css/style.css" rel="stylesheet" type="text/css">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <!-- script async src="https://www.googletagmanager.com/gtag/js?id=G-09KT1FJ0XF"></script-->
    <!--script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-09KT1FJ0XF');
    </script-->

    <meta name="description" content="Project page for 'Consistent Depth of Moving Objects in Video'">
</head>

<body>
    <p class="title">Consistent Depth of Moving Objects in Video</p>
    <p class="author">
        <span class="author"><a target="_blank" href="http://ztzhang.info/">Zhoutong Zhang</a>&nbsp;<sup>1,
                2</sup></span>
        <span class="author"><a target="_blank" href="http://people.csail.mit.edu/fcole/">Forrester
                Cole</a>&nbsp;<sup>1</sup></span>
        <span class="author"><a target="_blank" href="">Richard Tucker</a>&nbsp;<sup>1</sup></span>
        <span class="author"><a target="_blank" href="https://billf.mit.edu/">William T.
                Freeman</a>&nbsp;<sup>1,2</sup></span>
        <span class="author"><a target="_blank" href="http://people.csail.mit.edu/talidekel/">Tali
                Dekel</a>&nbsp;<sup>1, 3</sup></span>

    </p>
    <table border="0" align="center" class="affiliations" width="1200px">
        <tbody align="center">
            <tr>
                <td style="text-align: right; width: 15%"><img src="./assets/GoogleAI_logo.png" height="48" alt=""></td>
                <td style="text-align: left">&nbsp;<sup>1</sup>&nbsp;<a href="https://research.google.com/">Google
                        Research</a></td>
                <td style="text-align: right; width: 15%"><img src="./assets/mit_logo.png" height="38" alt=""></td>
                <td style="text-align: left">&nbsp;<sup>2</sup>&nbsp;<a href="http://www.mit.edu">MIT</a>
                </td>
                <td style="text-align: right; width: 15%"><img src="./assets/wis_logo.jpg" height="48" alt=""></td>
                <td style="text-align: left">&nbsp;<sup>3</sup>&nbsp;<a
                        href="https://www.weizmann.ac.il/pages/">Weizmann Institute of Science</a></td>
            </tr>
        </tbody>
    </table>
    <table width="999" border="0" align="center" class="menu">
        <tbody>
            <tr>
                <td align="center">| <a href="#paper">Paper</a> | <a href="#video">Video</a> | <a
                        href="#code">Code(Coming Soon)</a> | <a href="#BibTeX">BibTex</a>
                    |</td>
            </tr>
        </tbody>
    </table>
    <div class="container">
        <table width="999" border="0" align="center">
            <tbody>
                <tr>
                    <td colspan="4" align="center"><img src="./assets/teaser.gif" width='100%' alt=""
                            style="margin-top:10px"></td>
                </tr>
            </tbody>
        </table>
        <table width="200" border="0" align="center" style="table-layout: fixed; width: 100%">
            <tbody>
                <tr>
                    <td colspan="4" class="caption">
                        <p>
                            Our method estimates <em>geometrically and temporally consistent</em> depth from a general
                            video containing fast-moving objects and camera motion. The input video (a) contains a
                            continuous camera dolly motion following the moving person and puppy. This is a difficult
                            case for depth estimation due to the correlated motion between camera and subject. The video
                            is shown reprojected into the camera at frame t using our predicted depth (b), with
                            disparity maps of the re-projection shown below (c). On the bottom: x-t slices for the
                            horizontal line marked in red on frame t in (a). (d) The slice of the original video (top)
                            shows both camera and objects' motion (slanted lines in the background, twisted lines in the
                            foreground). The slices of the re-projected frames(e)(f) show the camera fixed relative
                            to the background (vertical lines), and foreground objects moving relative to the camera
                            (twisted lines).
                        </p>
                    </td>
                </tr>
            </tbody>
        </table>
        <!-- <p class="section">&nbsp;</p> -->
        <p><span class="section">Abstract</span> </p>
        <p>
            We present a method to estimate depth of a dynamic scene, containing arbitrary moving objects,
            from an ordinary video captured with a moving camera. We seek a geometrically and temporally consistent
            solution to this underconstrained problem: the depth predictions of corresponding points across frames
            should induce plausible, smooth motion in 3D. We formulate this objective in a new test-time training
            framework where a depth-prediction CNN is trained in tandem with an auxiliary scene-flow prediction
            MLP over the entire input video. By recursively unrolling the scene-flow prediction MLP over varying
            time steps, we compute both short-range scene flow to impose local smooth motion priors directly in
            3D, and long-range scene flow to impose multi-view consistency constraints with wide baselines.
            We demonstrate accurate and temporally coherent results on a variety of challenging videos
            containing diverse moving objects (pets, people, cars), as well as camera motion.
            Our depth maps give rise to a number of depth-and-motion aware video editing effects
            such as object and lighting insertion.<br>
        </p>

        <p class="section">&nbsp;</p>
        <p class="section">Video</p>
        <table width="200" border="0" align="center" text-align="center" id="video">
            <tbody>
                <tr>
                    <td text-align="center">
                        <p>5 min talk:</p>
                    </td>
                </tr>

                <tr>
                    <td><iframe width="800" height="450"
                            src="https://www.youtube-nocookie.com/embed/E3yuEdzCBcc?controls=0"
                            title="YouTube video player" frameborder="0"
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                            allowfullscreen></iframe>
                    </td>


                </tr>

                <tr>
                    <td align="center">
                        <p><a href='https://youtu.be/b4Sv7oh3n5I'>15-minute version is available on YouTube</a>.</p>
                    </td>
                </tr>
            </tbody>
        </table>
        <p class="section" id="results">Results</p>
        <table width="800" border="0" align="center">
            <tbody>
                <tr>
                    <td colspan="4" align="center"><img src="./assets/result_gif_5.gif" width="100%" alt=""
                            style="margin-top:10px"></td>
                </tr>
                <tr>
                    <td colspan="4" align="center"><img src="./assets/result_gif_4.gif" width="100%" alt=""
                            style="margin-top:10px"></td>
                </tr>
                <tr>
                    <td colspan="4" align="center"><img src="./assets/result_gif_3.gif" width="100%" alt=""
                            style="margin-top:10px"></td>
                </tr>
                <tr>
                    <td colspan="4" align="center"><img src="./assets/result_gif_2.gif" width="100%" alt=""
                            style="margin-top:10px"></td>
                </tr>
                <tr>
                    <td colspan="4" align="center"><img src="./assets/result_gif_1.gif" width="100%" alt=""
                            style="margin-top:10px"></td>
                </tr>
                <tr>
                    <td colspan="4" align="center"><img src="./assets/result_gif_0.gif" width="100%" alt=""
                            style="margin-top:10px"></td>
                </tr>
            </tbody>
        </table>

        <p class="section">&nbsp;</p>
        <p class="section" id="paper">Paper</p>
        <table width="940" border="0">
            <tbody>
                <tr>
                    <td height="100"><a href="./assets/Dynamic_Sceneflow_Siggraph2021.pdf"><img src="./assets/paper.png"
                                alt="" width="140" height="167"></a></td>
                    <td width="750">
                        <p><b>Consistent Depth of Moving Objects in Video</b><br>
                            Zhoutong Zhang, Forrester Cole, Richard Tucker, William T. Freeman, Tali Dekel<br>
                            <em>SIGGRAPH 2021.</em><br><br>
                            [<a href="./assets/Dynamic_Sceneflow_Siggraph2021.pdf">Paper</a>]
                        </p>
                    </td>
                </tr>
                <tr>
                    <td>

                    </td>
                </tr>
            </tbody>
        </table>


        <p class="section">&nbsp;</p>
        <p class="section">Supplementary Material</p>
        <table width="587" height="136" border="0">
            <tbody>
                <tr>
                    <td width="350"><a href='./supp/summary.html'><img src="./assets/supp.png" alt="" height="150"></a>
                    </td>

                </tr>
                <tr>
                    <td align="left">
                        <p>[<a href="./supp/summary.html">supplementary page</a>]</p>
                    </td>
                </tr>
            </tbody>
        </table>



        <p class="section">&nbsp;</p>
        <p class="section" id="code">Code</p>
        <table border="0">
            <tbody>
                <tr>
                    <td width="50"><a href=""><img src="./assets/github_logo.png" alt="" height="50"></a>
                    </td>
                    <td>
                        <p>[<a href="">code(Coming Soon)</a>]</p>
                    </td>

                </tr>

            </tbody>
        </table>
        <p class="section">&nbsp;</p>


        <p class="section" id="BibTeX">BibTeX</p>

        <blockquote>
            <pre>
@article{zhang2021consistent,
    title={Consistent depth of moving objects in video},
    author={Zhang, Zhoutong and Cole, Forrester and Tucker, Richard and Freeman, William T
            and Dekel, Tali},
    journal={ACM Transactions on Graphics (TOG)},
    volume={40},
    number={4},
    pages={1--12},
    year={2021},
    publisher={ACM New York, NY, USA}
}</pre>
        </blockquote>

        <p class="section">&nbsp;</p>


        <p class="section">Related Works</p>


        <table width="940" border="0">
            <tbody>
                <tr>

                    <a href="https://roxanneluo.github.io/Consistent-Video-Depth-Estimation/"><b>Consistent Video Depth
                            Estimation</b></a><br>
                    Xuan Luo, Jia-Bin Huang, Richard Szeliski, Kevin Matzen, Johannes Kopf.
                    <em>SIGGRAPH 2020.</em><br><br>
                </tr>
                <tr>

                    <a href="https://mannequin-depth.github.io/"><b>Learning the Depths of Moving People by Watching
                            Frozen People</b></a><br>
                    Zhengqi Li, Tali Dekel, Forrester Cole, Richard Tucker, Noah Snavely, Ce Liu, William T. Freeman.
                    <em> CVPR 2019</em>

                </tr>
            </tbody>
        </table>








    </div>


</body>

</html>